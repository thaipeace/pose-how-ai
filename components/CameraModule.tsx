"use client";

import clsx from "clsx";
import { useState, useRef, useEffect } from "react";
import SampleGallery from "./SampleGallery";

export default function CameraModule() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const [isStreaming, setIsStreaming] = useState(false);
  const [capturedImage, setCapturedImage] = useState<string | null>(null);

  // State l∆∞u g√≥c xoay v·∫≠t l√Ω (0, 90, -90)
  const [physicalAngle, setPhysicalAngle] = useState(0);

  const [analysisResult, setAnalysisResult] = useState<
    { light: string[]; subject: string[]; tech: string[] } | string | null
  >(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [showSamples, setShowSamples] = useState(false);

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    // Ki·ªÉm tra ƒë·ªãnh d·∫°ng
    if (!file.type.startsWith("image/")) {
      alert("Vui l√≤ng ch·ªçn t·ªáp h√¨nh ·∫£nh.");
      return;
    }

    const reader = new FileReader();
    reader.onload = (event) => {
      const base64 = event.target?.result as string;

      // D·ª´ng camera n·∫øu ƒëang b·∫≠t tr∆∞·ªõc khi hi·ªán ·∫£nh t·ª´ gallery
      if (videoRef.current?.srcObject) {
        const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
        tracks.forEach((track) => track.stop());
        setIsStreaming(false);
      }

      setCapturedImage(base64); // Hi·ªÉn th·ªã ·∫£nh v·ª´a ch·ªçn l√™n khung preview
      setAnalysisResult(null); // X√≥a k·∫øt qu·∫£ ph√¢n t√≠ch c≈©
    };
    reader.readAsDataURL(file);
  };

  const handleAnalyze = async () => {
    if (!capturedImage) return;

    setIsAnalyzing(true);
    setAnalysisResult(null);

    try {
      const response = await fetch("/api/analyze", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ image: capturedImage }),
      });

      const data = await response.json();

      if (data.success) {
        setAnalysisResult(data.advice.analysis);
      } else {
        throw new Error(data.error);
      }
    } catch (error) {
      setAnalysisResult("Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server.");
    } finally {
      setIsAnalyzing(false);
    }
  };

  // L·∫Øng nghe c·∫£m bi·∫øn chuy·ªÉn ƒë·ªông
  useEffect(() => {
    const handleDeviceOrientation = (event: DeviceOrientationEvent) => {
      const { beta, gamma } = event;

      // Logic x√°c ƒë·ªãnh h∆∞·ªõng m√°y d·ª±a tr√™n tr·ªçng l·ª±c
      // beta: nghi√™ng t·ªõi/lui (-180 ƒë·∫øn 180)
      // gamma: nghi√™ng tr√°i/ph·∫£i (-90 ƒë·∫øn 90)

      if (beta !== null && gamma !== null) {
        if (Math.abs(gamma) > 45) {
          // N·∫øu m√°y nghi√™ng sang b√™n h∆°n 45 ƒë·ªô => Landscape
          setPhysicalAngle(gamma > 0 ? 90 : -90);
        } else {
          // N·∫øu m√°y ƒë·ª©ng => Portrait
          setPhysicalAngle(0);
        }
      }
    };

    window.addEventListener("deviceorientation", handleDeviceOrientation);
    return () =>
      window.removeEventListener("deviceorientation", handleDeviceOrientation);
  }, []);

  const startCamera = async () => {
    setCapturedImage(null);
    setAnalysisResult(null);
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment",
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.onloadedmetadata = () => setIsStreaming(true);
      }
    } catch (err) {
      alert("L·ªói camera!");
    }
  };

  const takePhoto = () => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) return;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    // 1. L·∫•y th√¥ng tin xoay c·ªßa thi·∫øt b·ªã (0, 90, -90, 180)
    // Ngay c·∫£ khi UI b·ªã kh√≥a d·ªçc, gi√° tr·ªã n√†y v·∫´n thay ƒë·ªïi khi quay m√°y
    const angle = physicalAngle;

    const vWidth = video.videoWidth;
    const vHeight = video.videoHeight;

    // 2. Quy·∫øt ƒë·ªãnh k√≠ch th∆∞·ªõc Canvas d·ª±a tr√™n g√≥c xoay
    // N·∫øu m√°y n·∫±m ngang (90 ho·∫∑c -90), ta ho√°n ƒë·ªïi R·ªông/Cao ƒë·ªÉ ·∫£nh ra ƒë√∫ng chi·ªÅu ngang
    if (Math.abs(angle) === 90) {
      canvas.width = vHeight;
      canvas.height = vWidth;
    } else {
      canvas.width = vWidth;
      canvas.height = vHeight;
    }

    // 3. X·ª≠ l√Ω xoay context c·ªßa Canvas
    ctx.save();
    ctx.translate(canvas.width / 2, canvas.height / 2);
    ctx.rotate((angle * Math.PI) / 180);

    // V·∫Ω video v√†o t√¢m canvas ƒë√£ xoay
    // L∆∞u √Ω: khi ƒë√£ rotate context, ta v·∫Ω d·ª±a tr√™n k√≠ch th∆∞·ªõc g·ªëc c·ªßa video
    ctx.drawImage(video, -vWidth / 2, -vHeight / 2, vWidth, vHeight);
    ctx.restore();

    // 4. Xu·∫•t ·∫£nh
    setCapturedImage(canvas.toDataURL("image/jpeg", 0.8));

    // D·ª´ng camera
    (video.srcObject as MediaStream).getTracks().forEach((t) => t.stop());
    setIsStreaming(false);
  };

  return (
    <div className="flex flex-col gap-4 w-full max-w-md mx-auto p-4">
      <div className="relative aspect-[3/4] w-full bg-black rounded-3xl overflow-hidden shadow-2xl border-2 border-gray-800">
        {!capturedImage ? (
          <video
            ref={videoRef}
            autoPlay
            playsInline
            muted
            className="w-full h-full object-cover"
          />
        ) : (
          <img
            src={capturedImage}
            alt="Captured"
            className="w-full h-full object-contain bg-black"
          />
        )}

        {/* OVERLAY LOADING: C·ª±c k·ª≥ quan tr·ªçng ƒë·ªÉ ko c·∫£m th·∫•y ƒë∆° */}
        {isAnalyzing && (
          <div className="absolute inset-0 bg-black/70 backdrop-blur-sm flex flex-col items-center justify-center text-white p-6 text-center animate-in fade-in">
            <div className="w-12 h-12 border-4 border-indigo-400 border-t-transparent rounded-full animate-spin mb-4"></div>
            <p className="text-lg font-bold">ƒêang ph√¢n t√≠ch ·∫£nh...</p>
            <p className="text-xs text-gray-400 mt-2">
              Gemini ƒëang xem x√©t √°nh s√°ng v√† b·ªë c·ª•c c·ªßa b·∫°n
            </p>
          </div>
        )}

        {/* FALLBACK KHI L·ªñI */}
        {analysisResult == "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server." && (
          <div className="absolute inset-0 bg-rose-900/90 flex flex-col items-center justify-center text-white p-6 text-center">
            <span className="text-4xl mb-2">‚ö†Ô∏è</span>
            <p className="font-bold">K·∫øt n·ªëi th·∫•t b·∫°i</p>
            <p className="text-sm opacity-80 mb-4">
              S√≥ng y·∫øu ho·∫∑c Server qu√° t·∫£i.
            </p>
            <button
              onClick={handleAnalyze}
              className="px-6 py-2 bg-white text-rose-900 rounded-full font-bold active:scale-95"
            >
              Th·ª≠ l·∫°i
            </button>
          </div>
        )}
      </div>

      <canvas ref={canvasRef} className="hidden" />

      {analysisResult && typeof analysisResult !== "string" && (
        <div className="mt-4 space-y-4 p-5 bg-white border border-gray-100 rounded-3xl shadow-xl animate-in fade-in slide-in-from-bottom-4">
          <h3 className="text-lg font-bold text-gray-800 border-b pb-2">
            üí° H∆∞·ªõng d·∫´n ch·ª•p ƒë·∫πp
          </h3>

          {/* Nh√≥m √Ånh s√°ng */}
          <div>
            <h4 className="font-bold text-amber-600 text-sm uppercase">
              ‚òÄÔ∏è √Ånh s√°ng
            </h4>
            <ul className="list-disc list-inside text-gray-600 text-sm ml-2">
              {analysisResult.light.map((item: string, i: number) => (
                <li key={i}>{item}</li>
              ))}
            </ul>
          </div>

          {/* Nh√≥m Ch·ªß th·ªÉ */}
          <div>
            <h4 className="font-bold text-blue-600 text-sm uppercase">
              üßç Ch·ªß th·ªÉ
            </h4>
            <ul className="list-disc list-inside text-gray-600 text-sm ml-2">
              {analysisResult.subject.map((item: string, i: number) => (
                <li key={i}>{item}</li>
              ))}
            </ul>
          </div>

          {/* Nh√≥m Th√¥ng s·ªë k·ªπ thu·∫≠t */}
          <div>
            <h4 className="font-bold text-emerald-600 text-sm uppercase">
              ‚öôÔ∏è Th√¥ng s·ªë k·ªπ thu·∫≠t
            </h4>
            <ul className="list-disc list-inside text-gray-600 text-sm ml-2 bg-gray-50 p-2 rounded-lg">
              {analysisResult.tech.map((item: string, i: number) => (
                <li key={i}>{item}</li>
              ))}
            </ul>
          </div>
        </div>
      )}

      <div
        className={clsx("space-y-3", {
          "pointer-events-none opacity-50 bg-gray-200": isAnalyzing,
        })}
      >
        {/* Input file ·∫©n */}
        <input
          type="file"
          ref={fileInputRef}
          className="hidden"
          accept="image/*"
          onChange={handleFileUpload}
        />

        {isStreaming ? (
          <div className="grid grid-cols-2 gap-3">
            <button
              onClick={takePhoto}
              className="w-full py-4 bg-rose-600 text-white font-bold rounded-2xl shadow-lg active:scale-95 transition-transform"
            >
              üì∏ Ch·ª•p ·∫¢nh
            </button>
            <button
              onClick={() => fileInputRef.current?.click()}
              className="py-4 bg-gray-800 text-white font-bold rounded-2xl flex items-center justify-center gap-2"
            >
              üñºÔ∏è Th∆∞ vi·ªán
            </button>
          </div>
        ) : capturedImage ? (
          <div className="grid grid-cols-2 gap-3">
            <button
              onClick={startCamera}
              className="py-4 bg-gray-200 text-gray-800 font-bold rounded-2xl"
            >
              üîÑ L√†m l·∫°i
            </button>
            <button
              onClick={() => setShowSamples(true)}
              className="text-xs font-bold py-2 px-4 bg-white border border-gray-200 shadow-sm rounded-full text-indigo-600 active:scale-95 transition-all"
            >
              üñºÔ∏è Xem h√¨nh m·∫´u
            </button>
            {!analysisResult && (
              <button
                onClick={handleAnalyze}
                className="py-4 bg-indigo-600 text-white font-bold rounded-2xl shadow-lg shadow-indigo-200"
              >
                ‚ú® Ph√¢n t√≠ch
              </button>
            )}
          </div>
        ) : (
          <div className="grid grid-cols-2 gap-3">
            <button
              onClick={startCamera}
              className="w-full py-4 bg-blue-600 text-white font-bold rounded-2xl"
            >
              M·ªü Camera
            </button>
            <button
              onClick={() => fileInputRef.current?.click()}
              className="py-4 bg-gray-800 text-white font-bold rounded-2xl flex items-center justify-center gap-2"
            >
              üñºÔ∏è Th∆∞ vi·ªán
            </button>
          </div>
        )}
      </div>

      <p className="text-center text-[10px] text-gray-400 uppercase tracking-widest font-medium">
        H·ªó tr·ª£ Auto-Rotate Canvas
      </p>

      {/* HI·ªÇN TH·ªä MODAL KHI C·∫¶N */}
      {showSamples && <SampleGallery onClose={() => setShowSamples(false)} />}
    </div>
  );
}
